{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae92c1f-b702-4458-9930-8b549e606a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10f8f1",
   "metadata": {},
   "source": [
    "##  回顾：损失函数计算公式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82b0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:28:17.611526Z",
     "start_time": "2023-07-08T13:28:17.588817Z"
    }
   },
   "source": [
    "- $q(x)$：from student model，$p(x)$：from teacher model\n",
    "- 其次对于 $q(x), p(x)$ 在计算时需要加温度\n",
    "$$\n",
    "\\begin{split}\n",
    "L_{\\text{student}}&=\\alpha L_{\\text{CE}} + (1-\\alpha)L_{KD}\\\\\n",
    "&=\\alpha L_{\\text{CE}} + (1-\\alpha)T^2D_{KL}\\\\\n",
    "&=\\alpha L_{\\text{CE}} + (1-\\alpha)T^2\\sum_ip_i(x)\\log\\frac{p_i(x)}{q_i(x)}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "- 其中，KL 散度可以通过 `nn.KLDivLoss()` 函数来计算\n",
    "    - inputs ($q(x)$): log probabilities\n",
    "    - labels ($p(x)$): normal probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede970ba",
   "metadata": {},
   "source": [
    "## TrainerArguments & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf76fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:42:34.579255Z",
     "start_time": "2023-07-08T13:42:34.573911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59dde685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:42:36.134423Z",
     "start_time": "2023-07-08T13:42:36.126195Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DistillTrainingArguments(TrainingArguments):\n",
    "    # TrainingArguments: @dataclass\n",
    "    # 增加两个 KD 所需的参数参数\n",
    "    def __init__(self, *args, alpha=0.5, temperature=2., **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35763030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:45:33.019991Z",
     "start_time": "2023-07-08T13:45:33.005716Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DistillTrainer(Trainer):\n",
    "    \n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        # 增加 teacher_model 参数\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "\n",
    "    # 重写 trainer 中核心方法（forward 计算损失）\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        s_output = model(**inputs)\n",
    "        s_ce = s_output.loss\n",
    "        s_logits = s_output.logits\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            t_output = self.teacher_model(**inputs)\n",
    "            t_logits = t_output.logits\n",
    "        \n",
    "        loss_kl_fct = nn.KLDivLoss(reduction='batchmean')\n",
    "        loss_kd = self.args.temperature**2 * loss_kl_fct(F.log_softmax(s_logits/self.args.temperature, dim=-1),\n",
    "                                                         F.softmax(t_logits/self.args.temperature, dim=-1))\n",
    "        loss = self.args.alpha * s_ce + (1 - self.args.alpha) * loss_kd\n",
    "        return (loss, s_output) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd85c3",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2702dd",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f683fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:45:41.732252Z",
     "start_time": "2023-07-08T13:45:41.725945Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b79b20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:45:54.620037Z",
     "start_time": "2023-07-08T13:45:42.507852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# SequenceClassification\n",
    "clinc = load_dataset(\"clinc_oos\", \"plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c17cac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:45:57.176014Z",
     "start_time": "2023-07-08T13:45:57.167301Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 15250\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 3100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 5500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f258185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:46:17.612259Z",
     "start_time": "2023-07-08T13:46:17.599359Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['what expression would i use to say i love you if i were an italian',\n",
       "  \"can you tell me how to say 'i do not speak much spanish', in spanish\",\n",
       "  \"what is the equivalent of, 'life is good' in french\",\n",
       "  \"tell me how to say, 'it is a beautiful morning' in italian\",\n",
       "  'if i were mongolian, how would i say that i am a tourist',\n",
       "  \"how do i say 'hotel' in finnish\",\n",
       "  \"i need you to translate the sentence, 'we will be there soon' into portuguese\",\n",
       "  'please tell me how to ask for a taxi in french',\n",
       "  \"can you tell me how i would say, 'more bread please' in french\",\n",
       "  \"what is the correct way to say 'i am a visitor' in french\"],\n",
       " 'intent': [61, 61, 61, 61, 61, 61, 61, 61, 61, 61]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4366a862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:46:29.621894Z",
     "start_time": "2023-07-08T13:46:29.611922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = clinc['train'].features['intent']\n",
    "num_labels = intents.num_classes\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a4a0a9",
   "metadata": {},
   "source": [
    "### Student model 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "313668df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:46:48.960423Z",
     "start_time": "2023-07-08T13:46:48.949623Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a68a82b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:47:49.353462Z",
     "start_time": "2023-07-08T13:47:00.143015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 学生模型\n",
    "s_ckpt = 'distilbert-base-uncased'\n",
    "s_tokenizer = AutoTokenizer.from_pretrained(s_ckpt)\n",
    "\n",
    "# 教师模型\n",
    "t_ckpt = 'transformersbook/bert-base-uncased-finetuned-clinc'\n",
    "t_model = AutoModelForSequenceClassification.from_pretrained(t_ckpt, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30765bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:48:33.125442Z",
     "start_time": "2023-07-08T13:48:32.121377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 15250\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc_enc = clinc.map(\n",
    "    lambda batch: s_tokenizer(batch['text'], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "clinc_enc = clinc_enc.rename_columns({'intent': 'labels'})\n",
    "clinc_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9a08ae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:50:12.756586Z",
     "start_time": "2023-07-08T13:50:12.379492Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/nlp_study/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "s_training_args = DistillTrainingArguments(\n",
    "    output_dir='distilbert-base-uncased-ft-clinc', \n",
    "    evaluation_strategy='epoch', \n",
    "    num_train_epochs=5, \n",
    "    learning_rate=3e-4, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, \n",
    "    alpha=0.5, \n",
    "    weight_decay=0.01, \n",
    "    logging_strategy='epoch',\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"  # 这样就不会自动启用 W&B\n",
    ")\n",
    "\n",
    "s_config = AutoConfig.from_pretrained(\n",
    "    s_ckpt, \n",
    "    num_labels=num_labels, \n",
    "    id2label=t_model.config.id2label, \n",
    "    label2id=t_model.config.label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ba1a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:50:32.717059Z",
     "start_time": "2023-07-08T13:50:32.709207Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def student_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(s_ckpt, config=s_config).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294067e",
   "metadata": {},
   "source": [
    "## Student model 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8026a1ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:50:45.557236Z",
     "start_time": "2023-07-08T13:50:41.094296Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy_score = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9f99a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:51:05.438475Z",
     "start_time": "2023-07-08T13:51:05.430725Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 准确度指标计算函数\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return accuracy_score.compute(references=labels, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c635f0b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:54:04.344304Z",
     "start_time": "2023-07-08T13:51:39.054134Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1195' max='1195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1195/1195 02:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.239600</td>\n",
       "      <td>0.446824</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.331388</td>\n",
       "      <td>0.932258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.299509</td>\n",
       "      <td>0.945806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>0.950645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.276170</td>\n",
       "      <td>0.951613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1195, training_loss=0.4302276834783195, metrics={'train_runtime': 142.9024, 'train_samples_per_second': 533.581, 'train_steps_per_second': 8.362, 'total_flos': 427022126020140.0, 'train_loss': 0.4302276834783195, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_trainer = DistillTrainer(\n",
    "    model_init=student_init, \n",
    "    teacher_model=t_model, \n",
    "    args=s_training_args, \n",
    "    train_dataset=clinc_enc['train'], \n",
    "    eval_dataset=clinc_enc['validation'], \n",
    "    compute_metrics=compute_metrics, \n",
    "    tokenizer=s_tokenizer,\n",
    ")\n",
    "distill_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f6398eb-7094-4dc4-a333-e0bc8235f0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distill_trainer.save_model(\"./distilbert-base-uncased-ft-clinc\")  # 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "820b9f48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:54:24.687818Z",
     "start_time": "2023-07-08T13:54:24.678385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1195"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(15250 / (64 * 1)) * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c3a00",
   "metadata": {},
   "source": [
    "## Student model 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6a527d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:55:04.861128Z",
     "start_time": "2023-07-08T13:55:03.957835Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# ft_ckpt = 'lanchunhui/distilbert-base-uncased-ft-clinc'\n",
    "# distill_trainer.push_to_hub('finetune completed!')\n",
    "\n",
    "pipe = pipeline('text-classification', model='./distilbert-base-uncased-ft-clinc/', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df7cb41a-6140-4395-a476-e55bd8482b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'car_rental', 'score': 0.8687736988067627}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"\"\" Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_study",
   "language": "python",
   "name": "nlp_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
