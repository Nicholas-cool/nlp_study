{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b4e641",
   "metadata": {},
   "source": [
    "- 参考\n",
    "    - https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab1cd71-43a4-4bc7-9705-4512fa619918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6659387c",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201f0a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T09:51:31.664206Z",
     "start_time": "2023-06-10T09:51:31.653752Z"
    }
   },
   "source": [
    "- 数据并行是切数据（scattering inputs and gathering outputs），模型并行是切模型（shards）\n",
    "    - 模型并行：单卡放不下一份模型\n",
    "    - 将一份大模型，不同的层切分到不同的卡上\n",
    "- device_map：Huggingface 提供的参数\n",
    "- 模型并行 on ToyModel\n",
    "- 模型并行 on ResNet\n",
    "    - 不需要引入额外的 torch api 支持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6007bbf",
   "metadata": {},
   "source": [
    "## Huggingface 的支持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e0248",
   "metadata": {},
   "source": [
    "### device_map\n",
    "\n",
    "可选项：\"auto\", \"balanced\", \"balanced_low_0\", \"sequential\"\n",
    "\n",
    "`auto`：GPU(s) > CPU (RAM) > Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d5a4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:54:05.602719Z",
     "start_time": "2023-06-10T10:53:50.155859Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6105f3b1e824194a2a149ab77d07ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, \t cuda:0 \ttorch.float16\n",
      "1, \t cuda:0 \ttorch.int8\n",
      "2, \t cuda:0 \ttorch.int8\n",
      "3, \t cuda:0 \ttorch.int8\n",
      "4, \t cuda:0 \ttorch.int8\n",
      "5, \t cuda:0 \ttorch.int8\n",
      "6, \t cuda:0 \ttorch.int8\n",
      "7, \t cuda:0 \ttorch.int8\n",
      "8, \t cuda:0 \ttorch.float16\n",
      "9, \t cuda:0 \ttorch.float16\n",
      "10, \t cuda:0 \ttorch.int8\n",
      "11, \t cuda:0 \ttorch.int8\n",
      "12, \t cuda:0 \ttorch.int8\n",
      "13, \t cuda:0 \ttorch.int8\n",
      "14, \t cuda:0 \ttorch.int8\n",
      "15, \t cuda:0 \ttorch.int8\n",
      "16, \t cuda:0 \ttorch.int8\n",
      "17, \t cuda:0 \ttorch.float16\n",
      "18, \t cuda:0 \ttorch.float16\n",
      "19, \t cuda:0 \ttorch.int8\n",
      "20, \t cuda:0 \ttorch.int8\n",
      "21, \t cuda:0 \ttorch.int8\n",
      "22, \t cuda:0 \ttorch.int8\n",
      "23, \t cuda:0 \ttorch.int8\n",
      "24, \t cuda:0 \ttorch.int8\n",
      "25, \t cuda:0 \ttorch.int8\n",
      "26, \t cuda:0 \ttorch.float16\n",
      "27, \t cuda:0 \ttorch.float16\n",
      "28, \t cuda:0 \ttorch.int8\n",
      "29, \t cuda:0 \ttorch.int8\n",
      "30, \t cuda:0 \ttorch.int8\n",
      "31, \t cuda:0 \ttorch.int8\n",
      "32, \t cuda:0 \ttorch.int8\n",
      "33, \t cuda:0 \ttorch.int8\n",
      "34, \t cuda:0 \ttorch.int8\n",
      "35, \t cuda:0 \ttorch.float16\n",
      "36, \t cuda:0 \ttorch.float16\n",
      "37, \t cuda:0 \ttorch.int8\n",
      "38, \t cuda:0 \ttorch.int8\n",
      "39, \t cuda:0 \ttorch.int8\n",
      "40, \t cuda:0 \ttorch.int8\n",
      "41, \t cuda:0 \ttorch.int8\n",
      "42, \t cuda:0 \ttorch.int8\n",
      "43, \t cuda:0 \ttorch.int8\n",
      "44, \t cuda:0 \ttorch.float16\n",
      "45, \t cuda:0 \ttorch.float16\n",
      "46, \t cuda:0 \ttorch.int8\n",
      "47, \t cuda:0 \ttorch.int8\n",
      "48, \t cuda:0 \ttorch.int8\n",
      "49, \t cuda:0 \ttorch.int8\n",
      "50, \t cuda:0 \ttorch.int8\n",
      "51, \t cuda:0 \ttorch.int8\n",
      "52, \t cuda:0 \ttorch.int8\n",
      "53, \t cuda:0 \ttorch.float16\n",
      "54, \t cuda:0 \ttorch.float16\n",
      "55, \t cuda:0 \ttorch.int8\n",
      "56, \t cuda:0 \ttorch.int8\n",
      "57, \t cuda:0 \ttorch.int8\n",
      "58, \t cuda:0 \ttorch.int8\n",
      "59, \t cuda:0 \ttorch.int8\n",
      "60, \t cuda:0 \ttorch.int8\n",
      "61, \t cuda:0 \ttorch.int8\n",
      "62, \t cuda:0 \ttorch.float16\n",
      "63, \t cuda:0 \ttorch.float16\n",
      "64, \t cuda:0 \ttorch.int8\n",
      "65, \t cuda:0 \ttorch.int8\n",
      "66, \t cuda:0 \ttorch.int8\n",
      "67, \t cuda:0 \ttorch.int8\n",
      "68, \t cuda:0 \ttorch.int8\n",
      "69, \t cuda:0 \ttorch.int8\n",
      "70, \t cuda:0 \ttorch.int8\n",
      "71, \t cuda:0 \ttorch.float16\n",
      "72, \t cuda:0 \ttorch.float16\n",
      "73, \t cuda:0 \ttorch.int8\n",
      "74, \t cuda:0 \ttorch.int8\n",
      "75, \t cuda:0 \ttorch.int8\n",
      "76, \t cuda:0 \ttorch.int8\n",
      "77, \t cuda:0 \ttorch.int8\n",
      "78, \t cuda:0 \ttorch.int8\n",
      "79, \t cuda:0 \ttorch.int8\n",
      "80, \t cuda:0 \ttorch.float16\n",
      "81, \t cuda:0 \ttorch.float16\n",
      "82, \t cuda:0 \ttorch.int8\n",
      "83, \t cuda:0 \ttorch.int8\n",
      "84, \t cuda:0 \ttorch.int8\n",
      "85, \t cuda:0 \ttorch.int8\n",
      "86, \t cuda:0 \ttorch.int8\n",
      "87, \t cuda:0 \ttorch.int8\n",
      "88, \t cuda:0 \ttorch.int8\n",
      "89, \t cuda:0 \ttorch.float16\n",
      "90, \t cuda:0 \ttorch.float16\n",
      "91, \t cuda:0 \ttorch.int8\n",
      "92, \t cuda:0 \ttorch.int8\n",
      "93, \t cuda:0 \ttorch.int8\n",
      "94, \t cuda:0 \ttorch.int8\n",
      "95, \t cuda:0 \ttorch.int8\n",
      "96, \t cuda:0 \ttorch.int8\n",
      "97, \t cuda:0 \ttorch.int8\n",
      "98, \t cuda:0 \ttorch.float16\n",
      "99, \t cuda:0 \ttorch.float16\n",
      "100, \t cuda:0 \ttorch.int8\n",
      "101, \t cuda:0 \ttorch.int8\n",
      "102, \t cuda:0 \ttorch.int8\n",
      "103, \t cuda:0 \ttorch.int8\n",
      "104, \t cuda:0 \ttorch.int8\n",
      "105, \t cuda:0 \ttorch.int8\n",
      "106, \t cuda:0 \ttorch.int8\n",
      "107, \t cuda:0 \ttorch.float16\n",
      "108, \t cuda:0 \ttorch.float16\n",
      "109, \t cuda:0 \ttorch.int8\n",
      "110, \t cuda:0 \ttorch.int8\n",
      "111, \t cuda:0 \ttorch.int8\n",
      "112, \t cuda:0 \ttorch.int8\n",
      "113, \t cuda:0 \ttorch.int8\n",
      "114, \t cuda:0 \ttorch.int8\n",
      "115, \t cuda:0 \ttorch.int8\n",
      "116, \t cuda:0 \ttorch.float16\n",
      "117, \t cuda:0 \ttorch.float16\n",
      "118, \t cuda:0 \ttorch.int8\n",
      "119, \t cuda:0 \ttorch.int8\n",
      "120, \t cuda:0 \ttorch.int8\n",
      "121, \t cuda:0 \ttorch.int8\n",
      "122, \t cuda:0 \ttorch.int8\n",
      "123, \t cuda:0 \ttorch.int8\n",
      "124, \t cuda:0 \ttorch.int8\n",
      "125, \t cuda:0 \ttorch.float16\n",
      "126, \t cuda:0 \ttorch.float16\n",
      "127, \t cuda:1 \ttorch.int8\n",
      "128, \t cuda:1 \ttorch.int8\n",
      "129, \t cuda:1 \ttorch.int8\n",
      "130, \t cuda:1 \ttorch.int8\n",
      "131, \t cuda:1 \ttorch.int8\n",
      "132, \t cuda:1 \ttorch.int8\n",
      "133, \t cuda:1 \ttorch.int8\n",
      "134, \t cuda:1 \ttorch.float16\n",
      "135, \t cuda:1 \ttorch.float16\n",
      "136, \t cuda:1 \ttorch.int8\n",
      "137, \t cuda:1 \ttorch.int8\n",
      "138, \t cuda:1 \ttorch.int8\n",
      "139, \t cuda:1 \ttorch.int8\n",
      "140, \t cuda:1 \ttorch.int8\n",
      "141, \t cuda:1 \ttorch.int8\n",
      "142, \t cuda:1 \ttorch.int8\n",
      "143, \t cuda:1 \ttorch.float16\n",
      "144, \t cuda:1 \ttorch.float16\n",
      "145, \t cuda:1 \ttorch.int8\n",
      "146, \t cuda:1 \ttorch.int8\n",
      "147, \t cuda:1 \ttorch.int8\n",
      "148, \t cuda:1 \ttorch.int8\n",
      "149, \t cuda:1 \ttorch.int8\n",
      "150, \t cuda:1 \ttorch.int8\n",
      "151, \t cuda:1 \ttorch.int8\n",
      "152, \t cuda:1 \ttorch.float16\n",
      "153, \t cuda:1 \ttorch.float16\n",
      "154, \t cuda:1 \ttorch.int8\n",
      "155, \t cuda:1 \ttorch.int8\n",
      "156, \t cuda:1 \ttorch.int8\n",
      "157, \t cuda:1 \ttorch.int8\n",
      "158, \t cuda:1 \ttorch.int8\n",
      "159, \t cuda:1 \ttorch.int8\n",
      "160, \t cuda:1 \ttorch.int8\n",
      "161, \t cuda:1 \ttorch.float16\n",
      "162, \t cuda:1 \ttorch.float16\n",
      "163, \t cuda:1 \ttorch.int8\n",
      "164, \t cuda:1 \ttorch.int8\n",
      "165, \t cuda:1 \ttorch.int8\n",
      "166, \t cuda:1 \ttorch.int8\n",
      "167, \t cuda:1 \ttorch.int8\n",
      "168, \t cuda:1 \ttorch.int8\n",
      "169, \t cuda:1 \ttorch.int8\n",
      "170, \t cuda:1 \ttorch.float16\n",
      "171, \t cuda:1 \ttorch.float16\n",
      "172, \t cuda:1 \ttorch.int8\n",
      "173, \t cuda:1 \ttorch.int8\n",
      "174, \t cuda:1 \ttorch.int8\n",
      "175, \t cuda:1 \ttorch.int8\n",
      "176, \t cuda:1 \ttorch.int8\n",
      "177, \t cuda:1 \ttorch.int8\n",
      "178, \t cuda:1 \ttorch.int8\n",
      "179, \t cuda:1 \ttorch.float16\n",
      "180, \t cuda:1 \ttorch.float16\n",
      "181, \t cuda:1 \ttorch.int8\n",
      "182, \t cuda:1 \ttorch.int8\n",
      "183, \t cuda:1 \ttorch.int8\n",
      "184, \t cuda:1 \ttorch.int8\n",
      "185, \t cuda:1 \ttorch.int8\n",
      "186, \t cuda:1 \ttorch.int8\n",
      "187, \t cuda:1 \ttorch.int8\n",
      "188, \t cuda:1 \ttorch.float16\n",
      "189, \t cuda:1 \ttorch.float16\n",
      "190, \t cuda:1 \ttorch.int8\n",
      "191, \t cuda:1 \ttorch.int8\n",
      "192, \t cuda:1 \ttorch.int8\n",
      "193, \t cuda:1 \ttorch.int8\n",
      "194, \t cuda:1 \ttorch.int8\n",
      "195, \t cuda:1 \ttorch.int8\n",
      "196, \t cuda:1 \ttorch.int8\n",
      "197, \t cuda:1 \ttorch.float16\n",
      "198, \t cuda:1 \ttorch.float16\n",
      "199, \t cuda:1 \ttorch.int8\n",
      "200, \t cuda:1 \ttorch.int8\n",
      "201, \t cuda:1 \ttorch.int8\n",
      "202, \t cuda:1 \ttorch.int8\n",
      "203, \t cuda:1 \ttorch.int8\n",
      "204, \t cuda:1 \ttorch.int8\n",
      "205, \t cuda:1 \ttorch.int8\n",
      "206, \t cuda:1 \ttorch.float16\n",
      "207, \t cuda:1 \ttorch.float16\n",
      "208, \t cuda:1 \ttorch.int8\n",
      "209, \t cuda:1 \ttorch.int8\n",
      "210, \t cuda:1 \ttorch.int8\n",
      "211, \t cuda:1 \ttorch.int8\n",
      "212, \t cuda:1 \ttorch.int8\n",
      "213, \t cuda:1 \ttorch.int8\n",
      "214, \t cuda:1 \ttorch.int8\n",
      "215, \t cuda:1 \ttorch.float16\n",
      "216, \t cuda:1 \ttorch.float16\n",
      "217, \t cuda:1 \ttorch.int8\n",
      "218, \t cuda:1 \ttorch.int8\n",
      "219, \t cuda:1 \ttorch.int8\n",
      "220, \t cuda:1 \ttorch.int8\n",
      "221, \t cuda:1 \ttorch.int8\n",
      "222, \t cuda:1 \ttorch.int8\n",
      "223, \t cuda:1 \ttorch.int8\n",
      "224, \t cuda:1 \ttorch.float16\n",
      "225, \t cuda:1 \ttorch.float16\n",
      "226, \t cuda:1 \ttorch.int8\n",
      "227, \t cuda:1 \ttorch.int8\n",
      "228, \t cuda:1 \ttorch.int8\n",
      "229, \t cuda:1 \ttorch.int8\n",
      "230, \t cuda:1 \ttorch.int8\n",
      "231, \t cuda:1 \ttorch.int8\n",
      "232, \t cuda:1 \ttorch.int8\n",
      "233, \t cuda:1 \ttorch.float16\n",
      "234, \t cuda:1 \ttorch.float16\n",
      "235, \t cuda:1 \ttorch.int8\n",
      "236, \t cuda:1 \ttorch.int8\n",
      "237, \t cuda:1 \ttorch.int8\n",
      "238, \t cuda:1 \ttorch.int8\n",
      "239, \t cuda:1 \ttorch.int8\n",
      "240, \t cuda:1 \ttorch.int8\n",
      "241, \t cuda:1 \ttorch.int8\n",
      "242, \t cuda:1 \ttorch.float16\n",
      "243, \t cuda:1 \ttorch.float16\n",
      "244, \t cuda:1 \ttorch.int8\n",
      "245, \t cuda:1 \ttorch.int8\n",
      "246, \t cuda:1 \ttorch.int8\n",
      "247, \t cuda:1 \ttorch.int8\n",
      "248, \t cuda:1 \ttorch.int8\n",
      "249, \t cuda:1 \ttorch.int8\n",
      "250, \t cuda:1 \ttorch.int8\n",
      "251, \t cuda:1 \ttorch.float16\n",
      "252, \t cuda:1 \ttorch.float16\n",
      "253, \t cuda:1 \ttorch.int8\n",
      "254, \t cuda:1 \ttorch.int8\n",
      "255, \t cuda:1 \ttorch.int8\n",
      "256, \t cuda:1 \ttorch.int8\n",
      "257, \t cuda:1 \ttorch.int8\n",
      "258, \t cuda:1 \ttorch.int8\n",
      "259, \t cuda:1 \ttorch.int8\n",
      "260, \t cuda:1 \ttorch.float16\n",
      "261, \t cuda:1 \ttorch.float16\n",
      "262, \t cuda:1 \ttorch.int8\n",
      "263, \t cuda:1 \ttorch.int8\n",
      "264, \t cuda:1 \ttorch.int8\n",
      "265, \t cuda:1 \ttorch.int8\n",
      "266, \t cuda:1 \ttorch.int8\n",
      "267, \t cuda:1 \ttorch.int8\n",
      "268, \t cuda:1 \ttorch.int8\n",
      "269, \t cuda:1 \ttorch.float16\n",
      "270, \t cuda:1 \ttorch.float16\n",
      "271, \t cuda:1 \ttorch.int8\n",
      "272, \t cuda:1 \ttorch.int8\n",
      "273, \t cuda:1 \ttorch.int8\n",
      "274, \t cuda:1 \ttorch.int8\n",
      "275, \t cuda:1 \ttorch.int8\n",
      "276, \t cuda:1 \ttorch.int8\n",
      "277, \t cuda:1 \ttorch.int8\n",
      "278, \t cuda:1 \ttorch.float16\n",
      "279, \t cuda:1 \ttorch.float16\n",
      "280, \t cuda:1 \ttorch.int8\n",
      "281, \t cuda:1 \ttorch.int8\n",
      "282, \t cuda:1 \ttorch.int8\n",
      "283, \t cuda:1 \ttorch.int8\n",
      "284, \t cuda:1 \ttorch.int8\n",
      "285, \t cuda:1 \ttorch.int8\n",
      "286, \t cuda:1 \ttorch.int8\n",
      "287, \t cuda:1 \ttorch.float16\n",
      "288, \t cuda:1 \ttorch.float16\n",
      "289, \t cuda:1 \ttorch.float16\n",
      "290, \t cuda:1 \ttorch.float16\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "for i, para in enumerate(model.named_parameters()):\n",
    "    # print(f'{i}, {para[0]}\\t {para[1].device} \\t{para[1].dtype}')\n",
    "    print(f'{i}, \\t {para[1].device} \\t{para[1].dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9c394",
   "metadata": {},
   "source": [
    "## Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb32a1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:55:22.734083Z",
     "start_time": "2023-06-10T10:55:21.401055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = torch.nn.Linear(10000, 1000).to('cuda:0')\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(1000, 5).to('cuda:1')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.net1(x.to('cuda:0')))\n",
    "        return self.net2(x.to('cuda:1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10c8ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:56:43.186416Z",
     "start_time": "2023-06-10T10:56:42.132385Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# watch -n 1 nvidia-smi\n",
    "model = ToyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f127b263-3a60-4870-98ec-c4b98896a652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToyModel(\n",
       "  (net1): Linear(in_features=10000, out_features=1000, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (net2): Linear(in_features=1000, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd8176a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:57:16.966789Z",
     "start_time": "2023-06-10T10:57:16.956120Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(model.net1.parameters())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5515ad52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:57:25.079872Z",
     "start_time": "2023-06-10T10:57:25.070508Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "print(next(model.net1.parameters()).device)\n",
    "print(next(model.net2.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e1999c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:57:39.312339Z",
     "start_time": "2023-06-10T10:57:39.205305Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 单次 forward 和 back-propagation 示例\n",
    "model = ToyModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs = model(torch.randn(20, 10000))\n",
    "labels = torch.randn(20, 5).to('cuda:1')\n",
    "loss_fn(outputs, labels).backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4662c7",
   "metadata": {},
   "source": [
    "## Split ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1e1e0",
   "metadata": {},
   "source": [
    "- 简单介绍下 ResNet\n",
    "\n",
    "```\n",
    "model = ResNet(block, layers, **kwargs)\n",
    "\n",
    "# resnet18\n",
    "_resnet(BasicBlock, [2, 2, 2, 2])\n",
    "# resnet34\n",
    "_resnet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "# resnet50\n",
    "_resnet(Bottleneck, [3, 4, 6, 3])\n",
    "# resnet101\n",
    "_resnet(Bottleneck, [3, 4, 23, 3])\n",
    "# resnet152\n",
    "_resnet(Bottleneck, [3, 8, 36, 3])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "593d7bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:59:32.643357Z",
     "start_time": "2023-06-10T10:59:32.420118Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "# from torchvision.models.resnet import resnet18, resnet34, resnet50, resnet101, resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9b2daab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:59:37.319217Z",
     "start_time": "2023-06-10T10:59:36.895405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resnet50\n",
    "model = ResNet(Bottleneck, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05996879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:59:40.283916Z",
     "start_time": "2023-06-10T10:59:40.274490Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1 => bn1 => relu => maxpool => layer1-layer4 => avgpool => fc\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b97a8782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:00:49.368357Z",
     "start_time": "2023-06-10T11:00:49.359729Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b4d3aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:00:50.573133Z",
     "start_time": "2023-06-10T11:00:50.468033Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
      "           Conv2d-13          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
      "             ReLU-15          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-16          [-1, 256, 32, 32]               0\n",
      "           Conv2d-17           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 32, 32]             128\n",
      "             ReLU-19           [-1, 64, 32, 32]               0\n",
      "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      "             ReLU-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "             ReLU-25          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 32, 32]             128\n",
      "             ReLU-29           [-1, 64, 32, 32]               0\n",
      "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      "             ReLU-32           [-1, 64, 32, 32]               0\n",
      "           Conv2d-33          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 32, 32]             512\n",
      "             ReLU-35          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-36          [-1, 256, 32, 32]               0\n",
      "           Conv2d-37          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "             ReLU-39          [-1, 128, 32, 32]               0\n",
      "           Conv2d-40          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 16, 16]             256\n",
      "             ReLU-42          [-1, 128, 16, 16]               0\n",
      "           Conv2d-43          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-45          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-47          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-57          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-58          [-1, 512, 16, 16]               0\n",
      "           Conv2d-59          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 16, 16]             256\n",
      "             ReLU-61          [-1, 128, 16, 16]               0\n",
      "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
      "             ReLU-64          [-1, 128, 16, 16]               0\n",
      "           Conv2d-65          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-67          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
      "           Conv2d-69          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 16, 16]             256\n",
      "             ReLU-71          [-1, 128, 16, 16]               0\n",
      "           Conv2d-72          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
      "             ReLU-74          [-1, 128, 16, 16]               0\n",
      "           Conv2d-75          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-77          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-78          [-1, 512, 16, 16]               0\n",
      "           Conv2d-79          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 16, 16]             512\n",
      "             ReLU-81          [-1, 256, 16, 16]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "           Conv2d-85           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-87           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-89           [-1, 1024, 8, 8]               0\n",
      "       Bottleneck-90           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-99           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-100           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-101            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 8, 8]             512\n",
      "            ReLU-103            [-1, 256, 8, 8]               0\n",
      "          Conv2d-104            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 8, 8]             512\n",
      "            ReLU-106            [-1, 256, 8, 8]               0\n",
      "          Conv2d-107           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-109           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-110           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-111            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 8, 8]             512\n",
      "            ReLU-113            [-1, 256, 8, 8]               0\n",
      "          Conv2d-114            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 8, 8]             512\n",
      "            ReLU-116            [-1, 256, 8, 8]               0\n",
      "          Conv2d-117           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-119           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-120           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-121            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 8, 8]             512\n",
      "            ReLU-123            [-1, 256, 8, 8]               0\n",
      "          Conv2d-124            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 8, 8]             512\n",
      "            ReLU-126            [-1, 256, 8, 8]               0\n",
      "          Conv2d-127           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-129           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-130           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-131            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 8, 8]             512\n",
      "            ReLU-133            [-1, 256, 8, 8]               0\n",
      "          Conv2d-134            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 8, 8]             512\n",
      "            ReLU-136            [-1, 256, 8, 8]               0\n",
      "          Conv2d-137           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-139           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-140           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-141            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-143            [-1, 512, 8, 8]               0\n",
      "          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-146            [-1, 512, 4, 4]               0\n",
      "          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-151           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-155            [-1, 512, 4, 4]               0\n",
      "          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-158            [-1, 512, 4, 4]               0\n",
      "          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-161           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-165            [-1, 512, 4, 4]               0\n",
      "          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-168            [-1, 512, 4, 4]               0\n",
      "          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-171           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 93.59\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 191.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 128, 128), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d6cf5f",
   "metadata": {},
   "source": [
    "### 自定义模型并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f20df8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:04:16.626624Z",
     "start_time": "2023-06-10T11:04:16.614728Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试 view 函数的功能\n",
    "t = torch.rand((2, 3, 4))\n",
    "print(t.shape)\n",
    "t.view(t.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "928d344b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:01:31.594634Z",
     "start_time": "2023-06-10T11:01:31.583933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelParallelResNet50(ResNet):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
    "        # conv1 => bn1 => relu => maxpool => layer1-layer4 => avgpool => fc\n",
    "        self.seq1 = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.layer1, \n",
    "            self.layer2\n",
    "        ).to('cuda:0')\n",
    "        \n",
    "        self.seq2 = nn.Sequential(\n",
    "            self.layer3, \n",
    "            self.layer4,\n",
    "            self.avgpool,\n",
    "        ).to('cuda:1')\n",
    "        \n",
    "        self.fc.to('cuda:1')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # model parts（layers） 的（卡间）串行\n",
    "        x = self.seq2(self.seq1(x).to('cuda:1'))\n",
    "        return self.fc(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "374455e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:04:56.872047Z",
     "start_time": "2023-06-10T11:04:56.864383Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_size(model):\n",
    "    return sum([para.numel() for para in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5aac0f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:05:24.032226Z",
     "start_time": "2023-06-10T11:05:23.624182Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size(ResNet(Bottleneck, [3, 4, 6, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af29fed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:05:34.089675Z",
     "start_time": "2023-06-10T11:05:33.757310Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size(ModelParallelResNet50())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b081a1",
   "metadata": {},
   "source": [
    "## Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfc12ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:07:13.763943Z",
     "start_time": "2023-06-10T11:07:13.751034Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9],\n",
      "        [8],\n",
      "        [1],\n",
      "        [0],\n",
      "        [6]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 测试生成 one-hot 标签\n",
    "num_classes = 10\n",
    "\n",
    "one_hot_indices = torch.LongTensor(5).random_(0, num_classes).view(5, 1)\n",
    "print(one_hot_indices)\n",
    "\n",
    "labels = torch.zeros(5, num_classes).scatter_(1, one_hot_indices, 1)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2573c3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:08:49.711577Z",
     "start_time": "2023-06-10T11:08:49.697409Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 1000\n",
    "num_batches = 3\n",
    "batch_size = 120\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    model.train(True)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 生成 one-hot 标签\n",
    "    one_hot_indices = torch.LongTensor(batch_size) \\\n",
    "                           .random_(0, num_classes) \\\n",
    "                           .view(batch_size, 1)\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        # generate random inputs and labels\n",
    "        # (b, c, w, h)\n",
    "        inputs = torch.randn(batch_size, 3, image_w, image_h)\n",
    "        # one hot：(batch_size, num_classes)，行粒度只有一个为1 （one-hot）\n",
    "        # scatter 的三个参数：dim, index, src\n",
    "        labels = torch.zeros(batch_size, num_classes) \\\n",
    "                      .scatter_(1, one_hot_indices, 1)\n",
    "\n",
    "        # run forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to('cuda:0'))\n",
    "        # print('outputs', outputs.shape)\n",
    "        # run backward pass\n",
    "        labels = labels.to(outputs.device)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce49d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:10:02.945687Z",
     "start_time": "2023-06-10T11:09:52.052107Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "num_repeat = 10\n",
    "stmt = \"train(model)\"\n",
    "\n",
    "# 模型并行（多卡）\n",
    "setup = \"model = ModelParallelResNet50()\"\n",
    "mp_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)\n",
    "\n",
    "# 单卡\n",
    "setup = \"import torchvision.models as models;\" + \\\n",
    "        \"model = models.resnet50(num_classes=num_classes).to('cuda:0')\"\n",
    "rn_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05cbd70d-d776-4324-b25d-72865b7796e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('Agg')\n",
    "\n",
    "def plot(means, stds, labels, fig_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(np.arange(len(means)), means, yerr=stds,\n",
    "           align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)\n",
    "    ax.set_ylabel('ResNet50 Execution Time (Second)')\n",
    "    ax.set_xticks(np.arange(len(means)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(fig_name)\n",
    "#     plt.close(fig)\n",
    "\n",
    "plot([mp_mean, rn_mean],\n",
    "     [mp_std, rn_std],\n",
    "     ['Model Parallel', 'Single GPU'],\n",
    "     'mp_vs_rn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8815235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:10:32.195022Z",
     "start_time": "2023-06-10T11:10:32.186272Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29085834696888924, 0.2570463016629219)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_mean, rn_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83edc6f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:10:33.784277Z",
     "start_time": "2023-06-10T11:10:33.774970Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13154067997565203"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mp_mean - rn_mean) / rn_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_study",
   "language": "python",
   "name": "nlp_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "169px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
