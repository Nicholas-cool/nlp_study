{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba757128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:27:53.887900Z",
     "start_time": "2024-02-10T07:27:53.880487Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f141ef35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:40:49.738794Z",
     "start_time": "2024-02-10T11:40:48.561750Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b677f3de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:47:18.137664Z",
     "start_time": "2024-02-10T11:47:18.128108Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[0;31mDocstring:\u001B[0m\n",
       "cosine_similarity(x1, x2, dim=1, eps=1e-8) -> Tensor\n",
       "\n",
       "Returns cosine similarity between ``x1`` and ``x2``, computed along dim. ``x1`` and ``x2`` must be broadcastable\n",
       "to a common shape. ``dim`` refers to the dimension in this common shape. Dimension ``dim`` of the output is\n",
       "squeezed (see :func:`torch.squeeze`), resulting in the\n",
       "output tensor having 1 fewer dimension.\n",
       "\n",
       ".. math ::\n",
       "    \\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2, \\epsilon) \\cdot \\max(\\Vert x_2 \\Vert _2, \\epsilon)}\n",
       "\n",
       "Supports :ref:`type promotion <type-promotion-doc>`.\n",
       "\n",
       "Args:\n",
       "    x1 (Tensor): First input.\n",
       "    x2 (Tensor): Second input.\n",
       "    dim (int, optional): Dimension along which cosine similarity is computed. Default: 1\n",
       "    eps (float, optional): Small value to avoid division by zero.\n",
       "        Default: 1e-8\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> input1 = torch.randn(100, 128)\n",
       "    >>> input2 = torch.randn(100, 128)\n",
       "    >>> output = F.cosine_similarity(input1, input2)\n",
       "    >>> print(output)\n",
       "\u001B[0;31mType:\u001B[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F.cosine_similarity??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66924fd8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$$\n",
    "\\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2, \\epsilon) \\cdot \\max(\\Vert x_2 \\Vert _2, \\epsilon)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b726b0f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:40:55.342213Z",
     "start_time": "2024-02-10T11:40:50.147635Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/nlp_study/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, InputExample, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527fff9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f1c09f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:29:26.646137Z",
     "start_time": "2024-02-10T07:29:26.637126Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8902c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:20:21.976722Z",
     "start_time": "2024-02-06T13:20:21.966710Z"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- `model[0]`: `token_embeddings` \n",
    "- `model[1]`: `sentence_embedding` (`pooling_mode_mean_tokens`)\n",
    "\n",
    "> 其他的 Pooling 方法（添加 cls token 进行 pooling）\n",
    "> ```\n",
    "> pooling_model = models.Pooling(word_embed_model.get_word_embedding_dimension(), \n",
    "                       pooling_mode='cls',\n",
    "                       pooling_mode_cls_token=True, \n",
    "                       pooling_mode_mean_tokens = False)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1718acd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a223df56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:51:35.305039Z",
     "start_time": "2024-02-10T11:51:35.299519Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_examples = [\n",
    "    InputExample(texts=['This is a positive pair', 'Where the distance will be minimized'], label=1),\n",
    "#   InputExample(texts=['This is a negative pair', 'Their distance will be increased'], label=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba6d2f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:51:36.458556Z",
     "start_time": "2024-02-10T11:51:36.450349Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sentences input\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6b7fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:51:37.709961Z",
     "start_time": "2024-02-10T11:51:37.694333Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.utils.data._utils.collate.default_collate(batch)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f2cc02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:52:11.927710Z",
     "start_time": "2024-02-10T11:52:11.908227Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3893, 3940,  102]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])},\n",
       "  {'input_ids': tensor([[  101,  2073,  1996,  3292,  2097,  2022, 18478,  2094,   102]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}],\n",
       " tensor([1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.collate_fn = model.smart_batching_collate\n",
    "batch = next(iter(train_dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645285e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba248a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- $(a,b)$: pair sentences embeddings\n",
    "\n",
    "$$\n",
    "\\frac12|a,b|^2, \\ell=1\\\\\n",
    "\\text{ReLU}^2(\\epsilon-|a,b|), \\ell=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9830794f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:53:03.816249Z",
     "start_time": "2024-02-10T11:53:03.777977Z"
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[0;31mInit signature:\u001B[0m\n",
       "\u001B[0mlosses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mContrastiveLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0mmodel\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'SentenceTransformer'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0mdistance_metric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m<\u001B[0m\u001B[0mfunction\u001B[0m \u001B[0mSiameseDistanceMetric\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m<\u001B[0m\u001B[0;32mlambda\u001B[0m\u001B[0;34m>\u001B[0m \u001B[0mat\u001B[0m \u001B[0;36m0x7f78730e9c10\u001B[0m\u001B[0;34m>\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0mmargin\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'float'\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0msize_average\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'bool'\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m'None'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;31mDocstring:\u001B[0m     \n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\u001B[0;31mSource:\u001B[0m        \n",
       "\u001B[0;32mclass\u001B[0m \u001B[0mContrastiveLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mModule\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mmodel\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mSentenceTransformer\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mdistance_metric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mSiameseDistanceMetric\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCOSINE_DISTANCE\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mmargin\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0msize_average\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0;34m\"\"\"\u001B[0m\n",
       "\u001B[0;34m        Contrastive loss. Expects as input two texts and a label of either 0 or 1. If the label == 1, then the distance between the\u001B[0m\n",
       "\u001B[0;34m        two embeddings is reduced. If the label == 0, then the distance between the embeddings is increased.\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m        Args:\u001B[0m\n",
       "\u001B[0;34m            model: SentenceTransformer model\u001B[0m\n",
       "\u001B[0;34m            distance_metric: Function that returns a distance between\u001B[0m\n",
       "\u001B[0;34m                two embeddings. The class SiameseDistanceMetric contains\u001B[0m\n",
       "\u001B[0;34m                pre-defined metrices that can be used\u001B[0m\n",
       "\u001B[0;34m            margin: Negative samples (label == 0) should have a distance\u001B[0m\n",
       "\u001B[0;34m                of at least the margin value.\u001B[0m\n",
       "\u001B[0;34m            size_average: Average by the size of the mini-batch.\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m        References:\u001B[0m\n",
       "\u001B[0;34m            * Further information: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\u001B[0m\n",
       "\u001B[0;34m            * `Training Examples > Quora Duplicate Questions <../../examples/training/quora_duplicate_questions/README.html>`_\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m        Requirements:\u001B[0m\n",
       "\u001B[0;34m            1. (anchor, positive/negative) pairs\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m        Inputs:\u001B[0m\n",
       "\u001B[0;34m            +-----------------------------------------------+------------------------------+\u001B[0m\n",
       "\u001B[0;34m            | Texts                                         | Labels                       |\u001B[0m\n",
       "\u001B[0;34m            +===============================================+==============================+\u001B[0m\n",
       "\u001B[0;34m            | (anchor, positive/negative) pairs             | 1 if positive, 0 if negative |\u001B[0m\n",
       "\u001B[0;34m            +-----------------------------------------------+------------------------------+\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m        Relations:\u001B[0m\n",
       "\u001B[0;34m            - :class:`OnlineContrastiveLoss` is similar, but uses hard positive and hard negative pairs.\u001B[0m\n",
       "\u001B[0;34m            It often yields better results.\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m        Example:\u001B[0m\n",
       "\u001B[0;34m            ::\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m                from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, losses\u001B[0m\n",
       "\u001B[0;34m                from datasets import Dataset\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m                model = SentenceTransformer(\"microsoft/mpnet-base\")\u001B[0m\n",
       "\u001B[0;34m                train_dataset = Dataset.from_dict({\u001B[0m\n",
       "\u001B[0;34m                    \"sentence1\": [\"It's nice weather outside today.\", \"He drove to work.\"],\u001B[0m\n",
       "\u001B[0;34m                    \"sentence2\": [\"It's so sunny.\", \"She walked to the store.\"],\u001B[0m\n",
       "\u001B[0;34m                    \"label\": [1, 0],\u001B[0m\n",
       "\u001B[0;34m                })\u001B[0m\n",
       "\u001B[0;34m                loss = losses.ContrastiveLoss(model)\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m                trainer = SentenceTransformerTrainer(\u001B[0m\n",
       "\u001B[0;34m                    model=model,\u001B[0m\n",
       "\u001B[0;34m                    train_dataset=train_dataset,\u001B[0m\n",
       "\u001B[0;34m                    loss=loss,\u001B[0m\n",
       "\u001B[0;34m                )\u001B[0m\n",
       "\u001B[0;34m                trainer.train()\u001B[0m\n",
       "\u001B[0;34m        \"\"\"\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistance_metric\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdistance_metric\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmargin\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmargin\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize_average\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msize_average\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0;32mdef\u001B[0m \u001B[0mget_config_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mdistance_metric_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistance_metric\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mvars\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSiameseDistanceMetric\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m            \u001B[0;32mif\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistance_metric\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m                \u001B[0mdistance_metric_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"SiameseDistanceMetric.{name}\"\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m                \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0;32mreturn\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"distance_metric\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mdistance_metric_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"margin\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmargin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"size_average\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize_average\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msentence_features\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mIterable\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mreps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msentence_feature\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"sentence_embedding\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0msentence_feature\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msentence_features\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0;32massert\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreps\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mrep_anchor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrep_other\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreps\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mdistances\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistance_metric\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrep_anchor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrep_other\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0mlosses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.5\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m            \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mdistances\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmargin\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mdistances\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0;32mreturn\u001B[0m \u001B[0mlosses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize_average\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mlosses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m    \u001B[0;32mdef\u001B[0m \u001B[0mcitation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n",
       "\u001B[0;34m\u001B[0m        \u001B[0;32mreturn\u001B[0m \u001B[0;34m\"\"\"\u001B[0m\n",
       "\u001B[0;34m@inproceedings{hadsell2006dimensionality,\u001B[0m\n",
       "\u001B[0;34m    author={Hadsell, R. and Chopra, S. and LeCun, Y.},\u001B[0m\n",
       "\u001B[0;34m    booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},\u001B[0m\n",
       "\u001B[0;34m    title={Dimensionality Reduction by Learning an Invariant Mapping},\u001B[0m\n",
       "\u001B[0;34m    year={2006},\u001B[0m\n",
       "\u001B[0;34m    volume={2},\u001B[0m\n",
       "\u001B[0;34m    number={},\u001B[0m\n",
       "\u001B[0;34m    pages={1735-1742},\u001B[0m\n",
       "\u001B[0;34m    doi={10.1109/CVPR.2006.100}\u001B[0m\n",
       "\u001B[0;34m}\u001B[0m\n",
       "\u001B[0;34m\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;31mFile:\u001B[0m           ~/miniconda3/envs/nlp_study/lib/python3.8/site-packages/sentence_transformers/losses/ContrastiveLoss.py\n",
       "\u001B[0;31mType:\u001B[0m           type\n",
       "\u001B[0;31mSubclasses:\u001B[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.ContrastiveLoss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecf14126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:53:28.511016Z",
     "start_time": "2024-02-10T11:53:28.504483Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = losses.ContrastiveLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58edd877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:53:35.119949Z",
     "start_time": "2024-02-10T11:53:35.107551Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522, 384])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_loss.named_parameters())[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9021827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:54:33.705798Z",
     "start_time": "2024-02-10T11:54:33.695614Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[0;31mSignature:\u001B[0m \u001B[0mtrain_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistance_metric\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;31mDocstring:\u001B[0m <no docstring>\n",
       "\u001B[0;31mSource:\u001B[0m        \u001B[0mCOSINE_DISTANCE\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcosine_similarity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;31mFile:\u001B[0m      ~/miniconda3/envs/nlp_study/lib/python3.8/site-packages/sentence_transformers/losses/ContrastiveLoss.py\n",
       "\u001B[0;31mType:\u001B[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SiameseDistanceMetric.COSINE_DISTANCE\n",
    "# lambda x, y: 1-F.cosine_similarity(x, y)\n",
    "train_loss.distance_metric??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b237e009",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9961e7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:54:48.207787Z",
     "start_time": "2024-02-10T11:54:48.193835Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3893, 3940,  102]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])},\n",
       "  {'input_ids': tensor([[  101,  2073,  1996,  3292,  2097,  2022, 18478,  2094,   102]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}],\n",
       " tensor([1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4c27ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:54:44.224366Z",
     "start_time": "2024-02-10T11:54:44.212258Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4769ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:36:21.454854Z",
     "start_time": "2024-02-10T07:36:21.444522Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c230cba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:55:38.981022Z",
     "start_time": "2024-02-10T11:55:38.965493Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3893, 3940,  102]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])},\n",
       " {'input_ids': tensor([[  101,  2073,  1996,  3292,  2097,  2022, 18478,  2094,   102]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = batch\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90a97a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:55:48.925478Z",
     "start_time": "2024-02-10T11:55:48.915808Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d083f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:56:09.239982Z",
     "start_time": "2024-02-10T11:56:09.230175Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_cpy = deepcopy(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd8f0fb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:36:34.779803Z",
     "start_time": "2024-02-10T07:36:34.536182Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2930,  0.3243, -0.6169, -0.0097, -0.1806], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1](model[0](features[0]))['sentence_embedding'][0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "629e3ed3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:36:36.347544Z",
     "start_time": "2024-02-10T07:36:36.322309Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2930,  0.3243, -0.6169, -0.0097, -0.1806], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sum(model[0](feature_cpy[0])['token_embeddings'], dim=1) / 7)[0, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae3b9f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Forward loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d1c1e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:57:32.448996Z",
     "start_time": "2024-02-10T11:57:32.220772Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sent1_embed = model(features[0])['sentence_embedding']\n",
    "sent2_embed = model(features[1])['sentence_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a743f680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:57:33.207867Z",
     "start_time": "2024-02-10T11:57:33.197853Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9867], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss.distance_metric(sent1_embed, sent2_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60c522aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:57:41.034095Z",
     "start_time": "2024-02-10T11:57:41.022562Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9867], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - F.cosine_similarity(sent1_embed, sent2_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48aa94c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:57:45.658073Z",
     "start_time": "2024-02-10T11:57:45.622113Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4868, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbb43dce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:36:51.684259Z",
     "start_time": "2024-02-10T07:36:51.672273Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4868], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2 * (1 - F.cosine_similarity(sent1_embed, sent2_embed)) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c1142",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pooling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2637e43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:58:48.216238Z",
     "start_time": "2024-02-10T11:58:48.197564Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3893, 3940,  102]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])},\n",
       " {'input_ids': tensor([[  101,  2073,  1996,  3292,  2097,  2022, 18478,  2094,   102]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples = [\n",
    "    InputExample(texts=['This is a positive pair', 'Where the distance will be minimized'], label=1),\n",
    "#     InputExample(texts=['This is a negative pair', 'Their distance will be increased'], label=0)\n",
    "]\n",
    "# sentences input \n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)\n",
    "train_dataloader.collate_fn = model.smart_batching_collate\n",
    "batch = next(iter(train_dataloader))\n",
    "# batch \n",
    "features, labels = batch\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb09482",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### pooling_mode_mean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1b96f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T11:59:35.706251Z",
     "start_time": "2024-02-10T11:58:55.237250Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_embed_model = models.Transformer('bert-base-uncased')\n",
    "# a pool function over the token embeddings\n",
    "pooling_model = models.Pooling(word_embed_model.get_word_embedding_dimension(), \n",
    "                               pooling_mode_cls_token=False, \n",
    "                               pooling_mode_mean_tokens=True, \n",
    "                               pooling_mode_max_tokens=False, \n",
    "                               pooling_mode_mean_sqrt_len_tokens=False)\n",
    "model = SentenceTransformer(modules=[word_embed_model, pooling_model], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35bee922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:43:10.970461Z",
     "start_time": "2024-02-10T07:43:10.937965Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0863, -0.2668,  0.5492, -0.4936, -0.1374], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(features[0])['sentence_embedding'][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d35825",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### cls pooling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18a3ce93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:43:15.284696Z",
     "start_time": "2024-02-10T07:43:14.404275Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_embed_model = models.Transformer('bert-base-uncased')\n",
    "# a pool function over the token embeddings\n",
    "pooling_model = models.Pooling(word_embed_model.get_word_embedding_dimension(), \n",
    "                               pooling_mode = 'cls',\n",
    "                               pooling_mode_cls_token=True, \n",
    "                               pooling_mode_mean_tokens = False)\n",
    "model = SentenceTransformer(modules=[word_embed_model, pooling_model], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e62ed51b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:43:16.619741Z",
     "start_time": "2024-02-10T07:43:16.589343Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1775, -0.0474,  0.1351, -0.3242, -0.5006], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(features[0])['sentence_embedding'][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4463ff06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### cls pooling from scartch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87bf071b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T12:00:18.856106Z",
     "start_time": "2024-02-10T12:00:18.814363Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0](features[0])['token_embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1128ee57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T07:45:08.243313Z",
     "start_time": "2024-02-10T07:45:08.208104Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1775, -0.0474,  0.1351, -0.3242, -0.5006], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0](features[0])['token_embeddings'][0, 0][:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_study",
   "language": "python",
   "name": "nlp_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}