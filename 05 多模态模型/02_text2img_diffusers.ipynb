{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3bcc15-dc05-4a7c-9e5a-cf3e4b565054",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df066b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 配置及导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f175e42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:10:50.947211Z",
     "start_time": "2023-04-20T16:10:49.173659Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a74461c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:10:51.769575Z",
     "start_time": "2023-04-20T16:10:51.761955Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1105'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.now().strftime('%m%d')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a415c9de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:10:53.059523Z",
     "start_time": "2023-04-20T16:10:53.048262Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4e1b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:11:07.811505Z",
     "start_time": "2023-04-20T16:11:07.803082Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dtype = torch.float16 if 'cuda' in device else torch.float32\n",
    "torch_dtype = torch.float32\n",
    "torch_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d3790",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model & Config & Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9ea43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "不同精度下，模型加载和运行所需显存量：\n",
    "\n",
    "- torch.float16\n",
    "    - load：3588MiB-8\n",
    "    - forward: 5896MiB-8\n",
    "- torch.float32\n",
    "    - load: 6268MiB-8\n",
    "    - forward: 11064MiB-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5304aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:11:22.363491Z",
     "start_time": "2023-04-20T16:11:18.476113Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3c5395bc7848a39dd88ab90211999a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained('runwayml/stable-diffusion-v1-5', \n",
    "                                               torch_dtype=torch_dtype).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23818318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:07:20.547562Z",
     "start_time": "2023-04-20T16:07:20.541012Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict([('in_channels', 3),\n",
       "            ('out_channels', 3),\n",
       "            ('down_block_types',\n",
       "             ['DownEncoderBlock2D',\n",
       "              'DownEncoderBlock2D',\n",
       "              'DownEncoderBlock2D',\n",
       "              'DownEncoderBlock2D']),\n",
       "            ('up_block_types',\n",
       "             ['UpDecoderBlock2D',\n",
       "              'UpDecoderBlock2D',\n",
       "              'UpDecoderBlock2D',\n",
       "              'UpDecoderBlock2D']),\n",
       "            ('block_out_channels', [128, 256, 512, 512]),\n",
       "            ('layers_per_block', 2),\n",
       "            ('act_fn', 'silu'),\n",
       "            ('latent_channels', 4),\n",
       "            ('norm_num_groups', 32),\n",
       "            ('sample_size', 512),\n",
       "            ('scaling_factor', 0.18215),\n",
       "            ('shift_factor', None),\n",
       "            ('latents_mean', None),\n",
       "            ('latents_std', None),\n",
       "            ('force_upcast', True),\n",
       "            ('use_quant_conv', True),\n",
       "            ('use_post_quant_conv', True),\n",
       "            ('mid_block_add_attention', True),\n",
       "            ('_use_default_values',\n",
       "             ['use_post_quant_conv',\n",
       "              'scaling_factor',\n",
       "              'force_upcast',\n",
       "              'latents_std',\n",
       "              'shift_factor',\n",
       "              'mid_block_add_attention',\n",
       "              'latents_mean',\n",
       "              'use_quant_conv']),\n",
       "            ('_class_name', 'AutoencoderKL'),\n",
       "            ('_diffusers_version', '0.6.0'),\n",
       "            ('_name_or_path',\n",
       "             '/root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/f03de327dd89b501a01da37fc5240cf4fdba85a1/vae')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.vae.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3f7c2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:07:23.268091Z",
     "start_time": "2023-04-20T16:07:23.258835Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict([('sample_size', 64),\n",
       "            ('in_channels', 4),\n",
       "            ('out_channels', 4),\n",
       "            ('center_input_sample', False),\n",
       "            ('flip_sin_to_cos', True),\n",
       "            ('freq_shift', 0),\n",
       "            ('down_block_types',\n",
       "             ['CrossAttnDownBlock2D',\n",
       "              'CrossAttnDownBlock2D',\n",
       "              'CrossAttnDownBlock2D',\n",
       "              'DownBlock2D']),\n",
       "            ('mid_block_type', 'UNetMidBlock2DCrossAttn'),\n",
       "            ('up_block_types',\n",
       "             ['UpBlock2D',\n",
       "              'CrossAttnUpBlock2D',\n",
       "              'CrossAttnUpBlock2D',\n",
       "              'CrossAttnUpBlock2D']),\n",
       "            ('only_cross_attention', False),\n",
       "            ('block_out_channels', [320, 640, 1280, 1280]),\n",
       "            ('layers_per_block', 2),\n",
       "            ('downsample_padding', 1),\n",
       "            ('mid_block_scale_factor', 1),\n",
       "            ('dropout', 0.0),\n",
       "            ('act_fn', 'silu'),\n",
       "            ('norm_num_groups', 32),\n",
       "            ('norm_eps', 1e-05),\n",
       "            ('cross_attention_dim', 768),\n",
       "            ('transformer_layers_per_block', 1),\n",
       "            ('reverse_transformer_layers_per_block', None),\n",
       "            ('encoder_hid_dim', None),\n",
       "            ('encoder_hid_dim_type', None),\n",
       "            ('attention_head_dim', 8),\n",
       "            ('num_attention_heads', None),\n",
       "            ('dual_cross_attention', False),\n",
       "            ('use_linear_projection', False),\n",
       "            ('class_embed_type', None),\n",
       "            ('addition_embed_type', None),\n",
       "            ('addition_time_embed_dim', None),\n",
       "            ('num_class_embeds', None),\n",
       "            ('upcast_attention', False),\n",
       "            ('resnet_time_scale_shift', 'default'),\n",
       "            ('resnet_skip_time_act', False),\n",
       "            ('resnet_out_scale_factor', 1.0),\n",
       "            ('time_embedding_type', 'positional'),\n",
       "            ('time_embedding_dim', None),\n",
       "            ('time_embedding_act_fn', None),\n",
       "            ('timestep_post_act', None),\n",
       "            ('time_cond_proj_dim', None),\n",
       "            ('conv_in_kernel', 3),\n",
       "            ('conv_out_kernel', 3),\n",
       "            ('projection_class_embeddings_input_dim', None),\n",
       "            ('attention_type', 'default'),\n",
       "            ('class_embeddings_concat', False),\n",
       "            ('mid_block_only_cross_attention', None),\n",
       "            ('cross_attention_norm', None),\n",
       "            ('addition_embed_type_num_heads', 64),\n",
       "            ('_use_default_values',\n",
       "             ['mid_block_only_cross_attention',\n",
       "              'transformer_layers_per_block',\n",
       "              'use_linear_projection',\n",
       "              'reverse_transformer_layers_per_block',\n",
       "              'resnet_out_scale_factor',\n",
       "              'upcast_attention',\n",
       "              'mid_block_type',\n",
       "              'num_attention_heads',\n",
       "              'time_cond_proj_dim',\n",
       "              'resnet_skip_time_act',\n",
       "              'dual_cross_attention',\n",
       "              'conv_out_kernel',\n",
       "              'time_embedding_type',\n",
       "              'only_cross_attention',\n",
       "              'attention_type',\n",
       "              'time_embedding_dim',\n",
       "              'addition_time_embed_dim',\n",
       "              'encoder_hid_dim',\n",
       "              'cross_attention_norm',\n",
       "              'class_embed_type',\n",
       "              'class_embeddings_concat',\n",
       "              'conv_in_kernel',\n",
       "              'resnet_time_scale_shift',\n",
       "              'addition_embed_type',\n",
       "              'projection_class_embeddings_input_dim',\n",
       "              'dropout',\n",
       "              'num_class_embeds',\n",
       "              'timestep_post_act',\n",
       "              'encoder_hid_dim_type',\n",
       "              'addition_embed_type_num_heads',\n",
       "              'time_embedding_act_fn']),\n",
       "            ('_class_name', 'UNet2DConditionModel'),\n",
       "            ('_diffusers_version', '0.6.0'),\n",
       "            ('_name_or_path',\n",
       "             '/root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/f03de327dd89b501a01da37fc5240cf4fdba85a1/unet')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.unet.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa026555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:11:34.502396Z",
     "start_time": "2023-04-20T16:11:34.499033Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a_prompt = 'best quality, extremely detailed'\n",
    "n_prompt = 'longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f1145b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:11:35.367667Z",
     "start_time": "2023-04-20T16:11:35.360012Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a photo of an astronaut riding a horse on mars, best quality, extremely detailed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'a photo of an astronaut riding a horse on mars'\n",
    "prompt = prompt + ', ' + a_prompt\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b37506b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:11:43.442295Z",
     "start_time": "2023-04-20T16:11:36.560959Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec45d9af61748eaa17c27be87879fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = pipe(prompt, negative_prompt=n_prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6c1156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:11:54.758340Z",
     "start_time": "2023-04-20T16:11:54.671868Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img.save(f'./results/image-{today}-{str(uuid.uuid4())[:8]}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_study",
   "language": "python",
   "name": "nlp_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}